rank	entry_id	cluster	distance	content
1	73	8	0.3872614800930023194	Testing classifier accuracy requires a labeled dataset. The gemma3 1b tuning exp 
2	89	9	0.3914967775344848632	Writing should prefer active voice and concrete nouns. The model classified the  
3	25	3	0.4150146543979644776	Prompt templates should avoid negation. Do not classify X as Y is less reliable  
4	57	6	0.4314482808113098145	JSON.generate produces a JSON string from a Ruby object. JSON.pretty_generate ad 
5	24	3	0.4329794645309448242	A classifier prompt that worked for Python code detection returned false negativ 
6	23	3	0.4430143535137176514	Zero-shot classification with gemma3 1b fails on edge cases. The model needs at  
7	78	8	0.4442079961299896241	Test queries are written to cover four categories: high-confidence matches, mixe 
8	35	4	0.4532687067985534667	The FTS5 tokenizer configuration porter unicode61 handles English morphological  
9	27	3	0.4576789438724517823	Temperature 0.0 does not guarantee deterministic output from gemma3 1b. Across 1 
10	28	3	0.4633354544639587402	Set all classifier prompts to temperature 0.0 despite non-determinism. Higher te 
11	90	9	0.4674060344696044921	Posts follow a consistent structure: TL;DR, setup, experiment, results, dead end 
12	22	3	0.470506131649017334	Tuned the screen classifier prompt from a binary yes/no format to a structured c 
13	16	2	0.4718808829784393311	nomic-embed-text is trained for search rather than classification. Its vectors c 
14	98	10	0.4831430017948150635	Log messages are sentences, not codes. stored entry #42 (decision), 3 triples ex 
15	93	10	0.4855315983295440674	Log entries include the tool name as a structured field, not embedded in the mes 
16	9	1	0.4903285205364227294	Each tool exposes exactly one subcommand interface: tool_name action. No flags,  
17	21	3	0.4904215931892395019	The gemma3 1b model says yes to anything technology-adjacent when given vague co 
18	30	3	0.4990046620368957519	Classifier prompts include a machine-readable output format: respond with exactl 
